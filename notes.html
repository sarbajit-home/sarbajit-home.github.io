<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>notes section</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

        <!-- Header -->
			<header id="header">
				<div class="inner">
					<ul class="icons">
						<li><a href="index.html" class="icon solid fa-home"><span class="label">Go to Home</span></a></li>
					</ul>
					<h1><strong>Notes Section</strong>
					</h1>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				

				<!-- Notes -->
					<section id="notes">
						<h2 class="icon solid fa-file-pdf"> Notes & Resources</h2>
						<p>Find a collection of my personal study notes, derivations and technical summaries in PDF format.</p>
						
						<div class="row">
        
                            <article class="col-6 col-12-xsmall">
                                <h3>Multilayer Perceptron</h3>
                                <p><blockquote>This note provides an overview of a basic neural networks. We derive the mathematical framework for forward propagation using sigmoid neurons and provide a detailed step-by-step derivation of the Backpropagation algorithm using the chain rule. Furthermore, we discuss the optimization of model parameters via Gradient Descent and the quantification of network performance through the Mean Squared Error cost function. This document serves as a self-contained reference for understanding the transition from single-neuron models to layered, trainable architectures.</blockquote></p>
                                <ul class="actions">
                                <li><a href="notes/MLP_notes.pdf" class="button small">Read Notes</a></li>
                                </ul>
                            </article>

                            <article class="col-6 col-12-xsmall">
                                <h3>Recurrent Neural Networks (RNN)</h3>
                                <p><blockquote>This note provides a comprehensive theoretical framework for RNNs. The document details the unique architecture of RNNs. A rigorous mathematical formulation is presented for the forward pass, defining the element-wise and matrix operations for updating hidden states and generating outputs using activation functions like tanh and softmax . The core of the analysis focuses on the derivation of Backpropagation Through Time (BPTT). Finally, the notes outline the training loop, utilizing these calculated gradients to optimize the network via gradient descent algorithms.</blockquote></p>
                                <ul class="actions">
                                <li><a href="notes/RNN_notes.pdf" class="button small">Read Notes</a></li>
                                </ul>
                            </article>
                        </div>

					</section>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>